{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Recogniotion using SIFT Feature and cobining SVM result with X gboost \n",
    "detecting face gender Male or Femal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Data Gathering \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading  the dataset Function that take the path of data set folder and read the image on gray level and sorted on Images list then encoded label to integer number and store it on Labels list \n",
    "(return two lists )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDataSet(path_of_dataSet):\n",
    "   Images_List=[]\n",
    "   labels_List=[]\n",
    "\n",
    "   # Reading ......\n",
    "   for directory_path in glob.glob(path_of_dataSet):\n",
    "       label = directory_path.split(\"\\\\\")[-1]\n",
    "       for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")): #jpg\n",
    "           img = cv2.imread(img_path,0)# 0 for indicate the  gray scale   \n",
    "           Images_List.append(img)\n",
    "           labels_List.append(label)\n",
    "   # Label Encode      \n",
    "   le = preprocessing.LabelEncoder()\n",
    "   le.fit (labels_List)\n",
    "   Encoded_labels_List = le.transform(labels_List)\n",
    "   Images_List = np.array(Images_List , dtype='object')\n",
    "   Encoded_labels_List = np.array(Encoded_labels_List)\n",
    "   return Images_List , Encoded_labels_List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Feature Extraction / Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the SIFT to extract the interesting Key points and descriptors for each Image (Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of key points is theta that will be tunning to get the best value for this data set (Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then return the descriptors list for each image as feature (Feature set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://github.com/Akhilesh64/Image-Classification-using-SIFT/blob/main/main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT(Images_List, thresh):\n",
    "\n",
    "  t0 = time.time()\n",
    "\n",
    "\n",
    "  def CalcFeatures(img, th):\n",
    "    sift = cv2.xfeatures2d.SIFT_create(th)\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des\n",
    "  \n",
    "  '''\n",
    "  All  Images list are passed through the CalcFeatures functions\n",
    "   which returns the descriptors which are appended to the features list and \n",
    "  then stacked vertically in the form of a numpy array.\n",
    "  '''\n",
    "\n",
    "  features = []\n",
    "  for img in Images_List:\n",
    "    img_des = CalcFeatures(img, thresh)\n",
    "    if img_des is not None:\n",
    "      features.append(img_des)\n",
    "  features = np.vstack(features)\n",
    "\n",
    "\n",
    "  k = 150\n",
    "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.1)\n",
    "  flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "  compactness, labels, centres = cv2.kmeans(features, k, None, criteria, 10, flags)\n",
    "\n",
    "  def bag_of_features(features, centres, k = 500):\n",
    "      vec = np.zeros((1, k))\n",
    "      for i in range(features.shape[0]):\n",
    "          feat = features[i]\n",
    "          diff = np.tile(feat, (k, 1)) - centres\n",
    "          dist = pow(((pow(diff, 2)).sum(axis = 1)), 0.5)\n",
    "          idx_dist = dist.argsort()\n",
    "          idx = idx_dist[0]\n",
    "          vec[0][idx] += 1\n",
    "      return vec\n",
    "\n",
    "  vec = []\n",
    "  for img in Images_List:\n",
    "    img_des = CalcFeatures(img, thresh)\n",
    "    if img_des is not None:\n",
    "      img_vec = bag_of_features(img_des, centres, k)\n",
    "      vec.append(img_vec)\n",
    "  vec = np.vstack(vec)\n",
    "\n",
    "  t1 = time.time()\n",
    "  \n",
    "  return vec, (t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two classification used on this step Support Vector Machine (SVM) and Xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the parameter used ( kernal and gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((kernel ))poly kernel have been choices because have return better accuracy the degree will be the default (The Best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((gamma)) will be 0.6 it's the best after tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Measurement calculated are  Accuracy , Confusion matrix and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier(DataSet,Label_List):\n",
    "     # Split to Train and Test\n",
    "     X_train, X_test, y_train, y_test = train_test_split(DataSet,Label_List,test_size=.2)\n",
    "                             \n",
    "     # define support vector classifier\n",
    "     svm = SVC(kernel='poly',gamma = 0.6) \n",
    "     svm.fit(X_train,y_train)\n",
    "     y_pred = svm.predict(X_test)\n",
    "\n",
    "     # calculate accuracy,confusion matrix, specificity, sensitive and Report\n",
    "     accuracy = accuracy_score(y_test, y_pred)\n",
    "     specificity = recall_score(y_test, y_pred,average= None)\n",
    "     sensitive = recall_score(np.logical_not(y_test) , np.logical_not(y_pred),average= None)\n",
    "     report = classification_report(y_test, y_pred,zero_division =1, target_names=['Female', 'Male'])\n",
    "     conf_mat = confusion_matrix(y_test, y_pred)\n",
    "     \n",
    "\n",
    "     return accuracy*100,conf_mat, specificity,sensitive,report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XgBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Measurement calculated are  Accuracy , Confusion matrix  and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_Classifier(DataSet,Label_List):\n",
    "    # Split to Train and Test\n",
    "     X_train, X_test, y_train, y_test = train_test_split(DataSet,Label_List,test_size=.2)\n",
    "    \n",
    "    # Classifcation\n",
    "     model = xgb.XGBClassifier()\n",
    "     model.fit(X_train,y_train)\n",
    "     y_pred = model.predict(X_test)\n",
    "     \n",
    "     # Caculate accuracy,confusion_matrix specificity,sensitive,report\n",
    "     accuracy= accuracy_score( y_pred,y_test)\n",
    "     conf_mat = confusion_matrix(y_test, y_pred)\n",
    "     specificity = recall_score(y_test, y_pred,average= None)\n",
    "     sensitive = recall_score(np.logical_not(y_test) , np.logical_not(y_pred),average= None)\n",
    "     report = classification_report(y_test, y_pred,zero_division =1, target_names=['Femal','male'])\n",
    "\n",
    "    \n",
    "     return accuracy*100,conf_mat ,specificity,sensitive,report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading data set from folder and get the Images and label list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- looping through different value of threshold ( 10, 26 ,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- getting the feature set then send it to classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating for a threshold of 15\n",
      "Accuracy 71.96969696969697\n",
      "Time Consuming  4.793995141983032\n",
      "Confusion Matrix  [[46 18]\n",
      " [19 49]]\n",
      "\n",
      "Calculating for a threshold of 20\n",
      "Accuracy 79.54545454545455\n",
      "Time Consuming  5.317986965179443\n",
      "Confusion Matrix  [[57  7]\n",
      " [20 48]]\n",
      "\n",
      "Calculating for a threshold of 25\n",
      "Accuracy 70.45454545454545\n",
      "Time Consuming  5.853569030761719\n",
      "Confusion Matrix  [[45 19]\n",
      " [20 48]]\n"
     ]
    }
   ],
   "source": [
    "Image_List,Label_list =ReadDataSet(r\"Data Set/*\")\n",
    "\n",
    "accuracy = []\n",
    "threshold = []\n",
    "SVM_report = [] \n",
    "for i in range(15,26,5): #SVM  15,26,5 \n",
    "  print('\\nCalculating for a threshold of {}'.format(i))\n",
    "  feature, time_consuming  = SIFT(Image_List,i)\n",
    "  data= SVM_Classifier(feature, Label_list)\n",
    "  accuracy.append(data[0])\n",
    "  threshold.append(i)\n",
    "  SVM_report.append([data[2],data[3],data[4],data[1]])\n",
    "  print('Accuracy', data[0])\n",
    "  print('Time Consuming ', time_consuming)\n",
    "  print('Confusion Matrix ',data[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Xgboost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- XgBoost_Classifier ------\n",
      "\n",
      "Calculating for a threshold of 10\n",
      "Accuracy 78.78787878787878\n",
      "Time Consuming  4.321120977401733\n",
      "Confusion Matrix  [[39 19]\n",
      " [ 9 65]]\n",
      "\n",
      "Calculating for a threshold of 15\n",
      "Accuracy 74.24242424242425\n",
      "Time Consuming  4.910719394683838\n",
      "Confusion Matrix  [[53 14]\n",
      " [20 45]]\n",
      "\n",
      "Calculating for a threshold of 20\n",
      "Accuracy 68.93939393939394\n",
      "Time Consuming  5.584532022476196\n",
      "Confusion Matrix  [[49 17]\n",
      " [24 42]]\n",
      "\n",
      "Calculating for a threshold of 25\n",
      "Accuracy 75.75757575757575\n",
      "Time Consuming  6.110931634902954\n",
      "Confusion Matrix  [[49 22]\n",
      " [10 51]]\n"
     ]
    }
   ],
   "source": [
    "print('----- XgBoost_Classifier ------')\n",
    "Xg_threshold = []\n",
    "Xg_accuracy = []\n",
    "Xg_report = []\n",
    "for i in range(10,26,5):\n",
    "  print('\\nCalculating for a threshold of {}'.format(i))\n",
    "  feature, time_consuming  = SIFT(Image_List,i)\n",
    "  xgboostdata= XgBoost_Classifier(feature, Label_list)\n",
    "  Xg_accuracy.append(xgboostdata[0])\n",
    "  Xg_threshold.append(i)\n",
    "  Xg_report.append([data[2],data[3],data[4],data[1]])\n",
    "  print('Accuracy', xgboostdata[0])\n",
    "  print('Time Consuming ', time_consuming)\n",
    "  print('Confusion Matrix ',xgboostdata[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the SVM and Xgboost classifier which classifier provide the highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ SVM have produce the high Accuracy_________\n",
      "on threshold 20\n",
      "Accuracy is  79.54545454545455\n",
      "specificity [0.890625   0.70588235]\n",
      "sensitive [0.70588235 0.890625  ]\n",
      "Confusion Matrix  [[57  7]\n",
      " [20 48]]\n",
      "Report               precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.74      0.89      0.81        64\n",
      "        Male       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.80       132\n",
      "   macro avg       0.81      0.80      0.79       132\n",
      "weighted avg       0.81      0.80      0.79       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_High_Acc = max(accuracy)\n",
    "Xgboost_High_Acc = max(Xg_accuracy)\n",
    "if SVM_High_Acc > Xgboost_High_Acc :\n",
    "    index = accuracy.index(SVM_High_Acc)\n",
    "    print('______ SVM have produce the high Accuracy_________')\n",
    "    print('on threshold',threshold[index])    \n",
    "    print('Accuracy is ',accuracy[index])\n",
    "    print('specificity',SVM_report[index][0])\n",
    "    print('sensitive',SVM_report[index][1])\n",
    "    print('Confusion Matrix ',SVM_report[index][3])\n",
    "    print('Report',SVM_report[index][2])\n",
    "else:\n",
    "    Xg_index = Xg_accuracy.index(Xgboost_High_Acc)\n",
    "    print('Xgboost have produce the high Accuracy')\n",
    "    print('on threshold',Xg_threshold[Xg_index]) \n",
    "    print('Accuracy is ',Xg_accuracy[Xg_index])\n",
    "    print('specificity',Xg_report[Xg_index][0])\n",
    "    print('sensitive',Xg_report[Xg_index][1])\n",
    "    print('Confusion Matrix ',Xg_report[Xg_index][3])\n",
    "    print('Report',Xg_report[Xg_index][2])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the result of two Classifer ( SVM and Xgboost) to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is exported successfully to Excel File \n"
     ]
    }
   ],
   "source": [
    "# Export SVM Result \n",
    "df = pd.DataFrame(columns=['threshold','accurecy'])\n",
    "values = [threshold, accuracy]\n",
    "for index,j in zip(df.columns,values):\n",
    "    df[index] = j\n",
    "\n",
    "df.to_excel('SVM Result.xlsx')\n",
    "\n",
    "# Export Xgboost Result \n",
    "df = pd.DataFrame(columns=['threshold','accurecy'])\n",
    "values = [Xg_threshold, Xg_accuracy]\n",
    "for index,j in zip(df.columns,values):\n",
    "    df[index] = j\n",
    "\n",
    "df.to_excel('Xgboost Result.xlsx')\n",
    "print('DataFrame is exported successfully to Excel File ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a41862677209d0f6c6f72b3b118395bce78e978d9d3b978a0de6483880a01472"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
